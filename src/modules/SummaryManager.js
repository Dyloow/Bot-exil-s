import OpenAI from 'openai';
import config from '../config/ConfigManager.js';
import logger from '../utils/Logger.js';
import { EmbedBuilder } from 'discord.js';

/**
 * G√®re les r√©sum√©s IA des conversations Discord
 */
class SummaryManager {
  constructor(client, guild) {
    this.client = client;
    this.guild = guild;
    
    // Initialiser OpenAI
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });

    // Cache pour √©viter les doublons
    this.recentSummaries = new Map();
    
    // Compteur de messages par channel
    this.messageCounters = new Map();
  }

  /**
   * G√©n√®re un r√©sum√© via commande
   */
  async generateSummaryCommand(message, args) {
    // V√©rifier les permissions
    const member = message.guild.members.cache.get(message.author.id);

    // Nombre de messages √† r√©sumer
    const count = parseInt(args[0]) || config.get('summary.maxMessages');
    
    if (count < 10 || count > 500) {
      await message.reply('Le nombre de messages doit √™tre entre 10 et 500.');
      return;
    }

    await message.reply(`G√©n√©ration du r√©sum√© des ${count} derniers messages...`);

    try {
      const summary = await this.generateSummary(message.channel, count);
      
      if (summary) {
        await this.sendSummary(message.channel, summary, count);
      } else {
        await message.reply('Impossible de g√©n√©rer le r√©sum√©.');
      }
    } catch (error) {
      logger.error('Erreur lors de la g√©n√©ration du r√©sum√©:', error);
      await message.reply('Une erreur est survenue lors de la g√©n√©ration du r√©sum√©.');
    }
  }

  /**
   * G√©n√®re un r√©sum√© pour un channel
   */
  async generateSummary(channel, messageCount = null) {
    try {
      const count = messageCount || config.get('summary.maxMessages');

      // Collecter les messages
      logger.info(`Collecte des messages pour #${channel.name}...`);
      const messages = await this.collectMessages(channel, count);

      logger.info(`${messages.length} messages collect√©s`);

      if (messages.length === 0) {
        logger.warn('Aucun message √† r√©sumer');
        return null;
      }

      // Pr√©-traiter les messages
      const processedText = this.preprocessMessages(messages);

      logger.info(`Texte trait√©: ${processedText.length} caract√®res`);

      if (!processedText || processedText.trim().length < 50) {
        logger.warn('Texte trait√© trop court pour g√©n√©rer un r√©sum√©');
        return null;
      }

      // Limiter les tokens
      const truncatedText = this.truncateToTokenLimit(processedText);

      // Appeler l'IA
      logger.info(`Appel √† l'IA pour r√©sumer ${messages.length} messages...`);
      const summary = await this.callAI(truncatedText, channel.name);

      // Enregistrer le r√©sum√©
      this.recentSummaries.set(channel.id, Date.now());

      // Log
      await logger.aiSummary(channel.name, messages.length, truncatedText.length);

      // R√©initialiser le compteur
      this.messageCounters.set(channel.id, 0);

      return summary;

    } catch (error) {
      logger.error('Erreur lors de la g√©n√©ration du r√©sum√©:', error);
      return null;
    }
  }

  /**
   * Collecte les messages d'un channel
   */
  async collectMessages(channel, limit) {
    const messages = [];
    const excludeBots = config.get('summary.excludeBotMessages');
    const minLength = config.get('summary.minMessageLength');

    try {
      // Fetch max 200 messages bruts pour √©viter d'√™tre trop lent
      const maxFetch = Math.min(limit * 2, 200);
      
      logger.info(`Fetch de max ${maxFetch} messages bruts...`);
      const fetchedMessages = await channel.messages.fetch({ limit: maxFetch });
      
      logger.info(`${fetchedMessages.size} messages r√©cup√©r√©s, filtrage...`);

      // Filtrer et limiter
      for (const [id, msg] of fetchedMessages) {
        // Filtrer les messages
        if (excludeBots && msg.author.bot) continue;
        if (msg.content.length < minLength) continue;
        if (msg.content.startsWith('!')) continue; // Ignorer les commandes
        
        messages.push({
          author: msg.author.username,
          content: msg.content,
          timestamp: msg.createdAt
        });

        // Arr√™ter si on a assez de messages
        if (messages.length >= limit) break;
      }

      // Inverser pour avoir l'ordre chronologique
      return messages.reverse();

    } catch (error) {
      logger.error('Erreur lors de la collecte des messages:', error);
      return [];
    }
  }

  /**
   * Pr√©-traite les messages pour l'IA
   */
  preprocessMessages(messages) {
    // Formater les messages
    const formatted = messages.map(msg => {
      // Nettoyer le contenu
      let content = msg.content
        .replace(/<@!?\d+>/g, '@user')  // Mentions
        .replace(/<#\d+>/g, '#channel')  // Channels
        .replace(/<:\w+:\d+>/g, '')      // Emojis custom
        .replace(/https?:\/\/\S+/g, '[lien]') // URLs
        .trim();

      // Format: [Auteur] message
      return `[${msg.author}] ${content}`;
    }).filter(msg => msg.length > 10);

    return formatted.join('\n');
  }

  /**
   * Tronque le texte pour respecter la limite de tokens
   */
  truncateToTokenLimit(text) {
    const maxTokens = config.get('summary.maxTokens');
    const maxChars = maxTokens * 4; // Approximation: 1 token ‚âà 4 caract√®res

    if (text.length <= maxChars) {
      return text;
    }

    logger.warn(`Texte tronqu√© de ${text.length} √† ${maxChars} caract√®res`);
    return text.substring(0, maxChars) + '\n[... messages suivants omis ...]';
  }

  /**
   * Appelle l'IA pour g√©n√©rer le r√©sum√©
   */
  async callAI(text, channelName) {
    try {
      logger.info(`Appel √† l'API OpenAI...`);
      
      const systemPrompt = config.get('ai.systemPrompt');
      const model = config.get('ai.model');
      const maxTokens = config.get('ai.maxTokensOutput');
      const temperature = config.get('ai.temperature');

      const requestParams = {
        model: model,
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: `Voici les messages du channel Discord #${channelName} √† r√©sumer :\n\n${text}`
          }
        ],
        max_tokens: maxTokens
      };

      // gpt-5-nano ne supporte que temperature=1 (d√©faut)
      if (!model.includes('gpt-5-nano')) {
        requestParams.temperature = temperature;
      }

      logger.info(`Envoi de la requ√™te √† OpenAI (model: ${model}, max_tokens: ${maxTokens})...`);
      const response = await this.openai.chat.completions.create(requestParams);
      
      logger.info(`R√©ponse re√ßue de OpenAI`);
      return response.choices[0].message.content;

    } catch (error) {
      logger.error('Erreur lors de l\'appel √† l\'API OpenAI:', error);
      throw error;
    }
  }

  /**
   * Envoie le r√©sum√© dans le channel
   */
  async sendSummary(channel, summary, messageCount) {
    const summaryChannelId = config.get('server.summaryChannelId');
    
    // V√©rifier que l'ID est valide (pas FROM_ENV ou REMPLACER)
    let targetChannel = channel;
    if (summaryChannelId && !summaryChannelId.includes('FROM_ENV') && !summaryChannelId.includes('REMPLACER')) {
      const configuredChannel = this.guild.channels.cache.get(summaryChannelId);
      if (configuredChannel) {
        targetChannel = configuredChannel;
      }
    }

    // Discord limite √† 4096 caract√®res pour la description d'un embed
    let truncatedSummary = summary;
    if (summary.length > 4000) {
      truncatedSummary = summary.substring(0, 3997) + '...';
      logger.warn(`R√©sum√© tronqu√© de ${summary.length} √† 4000 caract√®res`);
    }

    const embed = new EmbedBuilder()
      .setColor(0x3498db)
      .setTitle(`R√©sum√© - #${channel.name}`)
      .setDescription(truncatedSummary);

    try {
      await targetChannel.send({ embeds: [embed] });
      logger.info(`R√©sum√© envoy√© dans #${targetChannel.name}`);
    } catch (error) {
      logger.error('Erreur lors de l\'envoi du r√©sum√©:', error);
      throw error;
    }
  }

  /**
   * V√©rifie si le seuil automatique est atteint
   */
  async checkAutoTrigger(channel) {
    const threshold = config.get('summary.autoTriggerThreshold');
    if (!threshold || threshold <= 0) return;

    // Incr√©menter le compteur
    const currentCount = (this.messageCounters.get(channel.id) || 0) + 1;
    this.messageCounters.set(channel.id, currentCount);

    // V√©rifier le seuil
    if (currentCount >= threshold) {
      logger.info(`Seuil automatique atteint pour #${channel.name} (${currentCount} messages)`);
      
      // G√©n√©rer le r√©sum√© automatiquement
      const summary = await this.generateSummary(channel);
      if (summary) {
        await this.sendSummary(channel, summary, currentCount);
      }
    }
  }

  /**
   * G√©n√®re des r√©sum√©s pour tous les channels actifs (t√¢che planifi√©e)
   */
  async generateScheduledSummaries() {
    logger.info('üìÖ G√©n√©ration des r√©sum√©s planifi√©s...');

    const channels = this.guild.channels.cache.filter(ch => 
      ch.isTextBased() && !ch.name.includes('log')
    );

    let generated = 0;
    for (const [id, channel] of channels) {
      // V√©rifier si le channel a suffisamment de messages
      const messageCount = this.messageCounters.get(id) || 0;
      
      if (messageCount >= 50) { // Minimum de messages pour un r√©sum√© planifi√©
        const summary = await this.generateSummary(channel);
        if (summary) {
          await this.sendSummary(channel, summary, messageCount);
          generated++;
        }

        // Attendre 2 secondes entre chaque r√©sum√©
        await new Promise(resolve => setTimeout(resolve, 2000));
      }
    }

    logger.info(`${generated} r√©sum√©(s) planifi√©(s) g√©n√©r√©(s)`);
  }
}

export default SummaryManager;
